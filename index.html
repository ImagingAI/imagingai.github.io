<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dr. Craig Jones - Medical Imaging AI Researcher</title>
    <style>
        :root {
            --primary-color: #2c3e50;
            --secondary-color: #3498db;
            --accent-color: #1abc9c;
            --text-color: #333;
            --light-bg: #f9f9f9;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Helvetica Neue', Arial, sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            background-color: white;
        }

        header {
            background-color: var(--primary-color);
            color: white;
            padding: 2rem 0;
            text-align: center;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 2rem;
        }

        h1 {
            font-size: 2.5rem;
            margin-bottom: 1rem;
        }

        h2 {
            font-size: 2rem;
            margin: 2rem 0 1rem;
            color: var(--primary-color);
        }

        h3 {
            font-size: 1.5rem;
            margin: 1.5rem 0 0.5rem;
            color: var(--secondary-color);
        }

        p {
            margin-bottom: 1rem;
        }

        .profile {
            display: flex;
            align-items: center;
            gap: 2rem;
            margin: 3rem 0;
        }

        .profile-img {
            width: 200px;
            height: 200px;
            border-radius: 50%;
            object-fit: cover;
            border: 4px solid var(--secondary-color);
        }

        .profile-text {
            flex: 1;
        }

        section {
            margin: 4rem 0;
            scroll-margin-top: 2rem;
        }

        .projects {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 2rem;
        }

        .project-card {
            background-color: var(--light-bg);
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            transition: transform 0.3s ease;
        }

        .project-card:hover {
            transform: translateY(-5px);
        }

        .project-img {
            width: 100%;
            height: 200px;
            object-fit: cover;
        }

        .project-content {
            padding: 1.5rem;
        }

        .education, .publications {
            background-color: var(--light-bg);
            padding: 2rem;
            border-radius: 8px;
        }

        .education-item, .publication-item {
            margin-bottom: 1.5rem;
        }

        .year {
            font-weight: bold;
            color: var(--secondary-color);
        }

        footer {
            background-color: var(--primary-color);
            color: white;
            text-align: center;
            padding: 2rem 0;
            margin-top: 4rem;
        }

        .contact-info {
            display: flex;
            justify-content: center;
            gap: 2rem;
            margin-top: 1rem;
        }

        a {
            color: var(--secondary-color);
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        footer a {
            color: white;
        }

        nav {
            background-color: white;
            position: sticky;
            top: 0;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            z-index: 100;
        }

        nav ul {
            display: flex;
            justify-content: center;
            list-style: none;
            padding: 1rem 0;
        }

        nav li {
            margin: 0 1rem;
        }

        nav a {
            color: var(--primary-color);
            font-weight: bold;
        }

        .highlight {
            color: var(--accent-color);
        }
    </style>
</head>
<body>
    <header>
        <div class="container">
            <h1>Dr. Craig Jones</h1>
            <p style="font-size:1.5em;">Medical Imaging AI Researcher</p>
            <p>craig@imagingai.org</p>
        </div>
    </header>

    <nav>
        <ul>
            <li><a href="#about">About</a></li>
            <li><a href="#research">Research</a></li>
            <li><a href="#projects">Projects</a></li>
            <li><a href="#education">Education</a></li>
            <li><a href="#publications">Publications</a></li>
            <li><a href="#contact">Contact</a></li>
        </ul>
    </nav>

    <main class="container">
        <section id="about" class="profile">
            <img src="images/ckj.png" alt="Dr. Craig Jones" class="profile-img">
            <div class="profile-text">
                <h2>About Me</h2>
                <p>I am a Medical Imaging AI Researcher with expertise in developing advanced machine learning techniques for medical image analysis, diagnosis, and treatment planning. My research focuses on improving healthcare outcomes through innovative AI solutions.</p>
		<p>Currently, I am currently the Director of the IAMAI Center at NovaGen Research, and have my own Imaging Lab too.</p> 
		<p>As well, I am an <a href="https://engineering.jhu.edu/faculty/craig-jones/">Assistant Research Professor</a> in <a href=https://www.cs.jhu.edu/">Computer Science</a> at Johns Hopkins with cross appointments in <a href="https://www.hopkinsmedicine.org/wilmer/">Ophthalmology</a>, <a href="https://www.hopkinsmedicine.org/radiology">Radiology</a>, and <a href="https://www.hopkinsmedicine.org/gastroenterology-hepatology">Gastroenterology</a>.  I am a Co-Director of the <a href="https://rail.jhu.edu">Radiology AI Lab</a>. I have four PhD students and numerous MSc and undergraduate students working on computer science, medical image processing, deep learning, and AI modeling of medical imaging and non-imaging data.</p>
</p>
                <p>I integrate deep learning algorithms, computer vision techniques, and specialized medical knowledge to develop AI-assisted diagnostic systems for clinical applications. My computational tools augment medical researchers' capabilities by identifying subtle imaging biomarkers and patterns, enhancing diagnostic precision and workflow efficiency. My approach leverages multimodal medical imaging data through neural networks and transformer architectures, serving as decision support technology rather than replacement for expert clinical judgment.</p>
            </div>
        </section>

        <section id="research">
            <h2>Research Focus</h2>
            <p>My research spans several key areas in medical imaging AI:</p>
            <ul>
                <li><strong>Multimodal Analysis:</strong> Integrating information from multiple imaging modalities (MRI, CT, PET) along with EHR records and -omics for comprehensive diagnosis.</li>
                <li><strong>Longitudinal Prediction:</strong> Developing neural network architectures for disease progression and prediction from multiple arbitrary timepoints of imaging dat (along with other multi-modal data).</li>
                <li><strong>Uncertainty:</strong> Understanding how uncertainty plays into AI both related to the input (clean labels) and output.</li>
                <li><strong>Collaborations:</strong>My collaborations with medical researchers is an important aspect of my work as the collaboration and knowledge sharing is what will drive medical AI work.</li>
            </ul>
        </section>

        <section id="projects">
            <h2>Featured Projects</h2>
            <div class="projects">
                <div class="project-card">
                    <img src="images/eye3.png" alt="Project 1" class="project-img">
                    <div class="project-content">
                        <h3>AI-Driven Brain Tumor Segmentation</h3>
			<p>My active shape model research develops automated registration methods for ocular structures in CT images using point distribution models that can precisely locate and outline eye components despite image quality variations. This work addresses critical challenges in ophthalmology and radiation therapy treatment planning by providing accurate anatomical structure identification even when abnormalities are present. 
			<p>Future work will incorporate deep learning for improved feature detection, extend the model to handle pathological deformations, create multi-modal registration frameworks, and develop clinical decision support systems leveraging these models for treatment planning.</p>
                    </div>
                </div>

                <div class="project-card">
                    <img src="/api/placeholder/400/200" alt="Project 2" class="project-img">
                    <div class="project-content">
                        <h3>Lung Nodule Detection and Classification</h3>
                        <p>Created an end-to-end system for detecting and classifying pulmonary nodules in CT scans, reducing false positive rates by 30% compared to previous methods.</p>
                        <p>The system has been deployed in a clinical trial with [Partner Hospital] to assist radiologists in early lung cancer screening.</p>
                    </div>
                </div>

                <div class="project-card">
                    <img src="/api/placeholder/400/200" alt="Project 3" class="project-img">
                    <div class="project-content">
                        <h3>Federated Learning for Medical Imaging</h3>
                        <p>Pioneered a privacy-preserving federated learning framework that enables multiple healthcare institutions to collaboratively train AI models without sharing sensitive patient data.</p>
                        <p>This approach addresses key regulatory and privacy concerns in healthcare AI deployment.</p>
                    </div>
                </div>

                <div class="project-card">
                    <img src="/api/placeholder/400/200" alt="Project 4" class="project-img">
                    <div class="project-content">
                        <h3>Multimodal Fusion for Alzheimer's Diagnosis</h3>
                        <p>Developed a multimodal deep learning approach that combines structural MRI, FDG-PET, and clinical data for early diagnosis of Alzheimer's disease.</p>
                        <p>The model achieved 94% accuracy in identifying patients with mild cognitive impairment who progressed to Alzheimer's within 3 years.</p>
                    </div>
                </div>

                <div class="project-card">
                    <img src="/api/placeholder/400/200" alt="Project 5" class="project-img">
                    <div class="project-content">
                        <h3>Explainable AI for Radiology Reports</h3>
                        <p>Created an explainable AI system that generates human-readable justifications for its findings when analyzing chest X-rays, increasing radiologist trust and adoption.</p>
                        <p>This work addresses the "black box" nature of AI diagnostics and provides transparency in clinical decision support.</p>
                    </div>
                </div>
            </div>
        </section>

        <section id="education" class="education">
            <h2>Teaching and Scientific Advising</h2>

            <div class="education-item">
                <h3>Teaching</h3>
		<p>
		 I have taught "Radiology for Engineers" (EN.580.425) in the Biomedical Engineering department, covering MRI and Medical Imaging for post-graduate students and "Deep Learning for Medical Imaging" (EN.580.627).
In the Computer Science department, I designed and taught "Seminar Topics in Medical Image Processing" (EN.601.862) for post-graduate students, and taught "Computer Vision" (EN.601.461) to approximately 80 students. 
		</p>
            </div>

            <div class="education-item">
                <h3>Scientific Advising</h3>
		<p>I serve as a Scientific Advisor for the <a href="https://www.cameramriafrica.org/spark">SPrint AI training for AfRican medical imaging Knowledge translation (SPARK)</a> which is part of <a href="https://www.cameramriafrica.org">CAMERA</a> program to build expertise to enable Africa to use MRI to realize their healthcare needs. I teach several modules in the SPARK program including Medical Image Processing, UNet Segmentation, Deep Learning, and How to Write a Paper.</p>
            </div>

            <div class="education-item">
                <h3>Reviewer</h3>
		<p>Recent conferences and journals I have reviewed for include: British Journal of Ophthalmology; Computer Methods and Programs in Biomedicine; Artificial Intelligence in Medicine; Engineering; JAMA Ophthalmology; PlosOne; Physica Scripta, Ophthalmology Retina; MICCAI.
            </div>
        </section>

        <section id="education" class="education">
            <h2>Education & Training</h2>

            <div class="education-item">
                <h3>Ph.D. in Physics (Medical Biophysics)</h3>
                <p>University of British Columbia -- 1999 - 2003</p>
                <p>Thesis: T2 Decay Curve Acquisition and Analysis in MRI: Noise Considerations, Short T2 , and B1 Field Encoding</p>
                <p>Advisor: Prof. Alex Mackay and San Xang</p>
            </div>

            <div class="education-item">
                <h3>M.S. in Medical Biophysics</h3>
                <p>University of Western Ontario -- 1994 - 1997</p>
                <p>Thesis: Quantitative Multi-Component Analysis Using Fast Spin-Echo MRI</p>
            </div>

            <div class="education-item">
                <h3>B.Sc. (Honours) in Mathematics and Computing Science (First Class Standing)</h3>
                <p>Simon Fraser University -- 1988 - 1992</p>
            </div>

            <h3>Additional Training</h3>
            <div class="education-item">
                <h3>Postdoctoral Research Fellowship</h3>
                <p>F.M. Kirby Center, Kennedy Krieger Institute, Johns Hopkins University -- 2003 - 2006 </p>
                <p>Focus: My research centered on developing advanced quantitative MRI techniques for neurological applications, particularly focusing on novel contrast mechanisms like amide proton transfer (APT) imaging for brain tumors and magnetization transfer methods for spinal cord assessment. I applied early machine learning approaches to image processing challenges, including automated registration techniques and clustering algorithms for tissue classification, which established the foundation for my later work combining artificial intelligence with medical imaging.</p>
            </div>
        </section>

        <section id="publications" class="publications">
            <h2>Selected Publications</h2>

	    <p>
	    Below is a selection of recent papers from my full list of approximately 100 peer reviewed journal articles.
	    </p>
            <a href="https://scholar.google.com/citations?hl=en&user=uWxO67gAAAAJ&view_op=list_works&sortby=pubdate">View all publications →</a>

	    <h3>Recent Ophthalmology Publications</h3>
	    <ol style="margin-left: 3em;">
		  <li>Wang Y, Peng J, Dai Y, <strong>Jones C</strong>, Sair S, Shen J, Loizou N, Wu J, Hsu WC, Imami M, Yang L, Jiao Z, Zhang P, Bai H, "Enhancing vision-language models for medical imaging: bridging the 3D gap with innovative slice selection", NeurIPS D&B Track 2024.</li>

		  <li>TYA Liu, Y Liu, MS Gastonguay, D Midgett, N Kuo, Y Zhao, K Ullah, G Alexander, T Hartman, ND Koseoglu, <strong>C Jones</strong>, "Predicting Imminent Conversion to Exudative Age-related Macular Degeneration Using Multimodal Data and Ensemble Machine Learning", Ophthalmology Science. 2025. In Press. doi: https://doi.org/10.1016/j.xops.2025.100785</li>

		  <li>Cornelio A, Martinez AC, Lu H, <strong>Jones C</strong>, Kashani AH, "Rigid alignment method for secondary analyses of optical coherence tomography volumes", Biomed. Opt. Express 15, 938-952 (2024) https://doi.org/10.1364/BOE.508123.</li>

		  <li>Liu TYA, Koseoglu ND, <strong>Jones CK</strong>, "Self-Supervised Deep Learning—The Next Frontier", JAMA Ophthalmol. Published online February 8, 2024. doi:10.1001/jamaophthalmol.2023.6650.</li>

		  <li>Wu J, Koseoglu ND, <strong>Jones CK</strong>, Liu TYA. "Vision transformers: The next frontier for deep learning-based ophthalmic image analysis", Saudi Journal of Ophthalmology:, July 14, 2023. | DOI: 10.4103/sjopt.sjopt_91_23.</li>

		  <li><strong>Jones CK</strong>, Li B, Wu JH, Nakaguchi T, Xuan P, Liu TYA. "Comparative analysis of alignment algorithms for macular optical coherence tomography imaging", Int J Retin Vitr 2023;9(60) 2023, https://doi.org/10.1186/s40942-023-00497-2.</li>

		  <li>Kashani AH, Liu TYA, <strong>Jones CK</strong>. "Optical Coherence Tomography Angiography, Artificial Intelligence, and the Missing Capillaries", JAMA Ophthalmol. Published online May 25, 2023. doi:10.1001/jamaophthalmol.2023.1829.</li>

		  <li>Liu Y, Ota M, Han R, Siewerdsen J, Liu TYA, <strong>Jones CK</strong>, "Active Shape Model Registration of Ocular Structures in Computed Tomography Images." Physics in Medicine and Biology, 2022 (https://doi.org/10.1088/1361-6560/ac9a98).</li>

		  <li>Liu TY, Ling C, Hahn L, <strong>Jones CK</strong>, Boon C, Singh M. "Prediction of Visual Impairment in Retinitis Pigmentosa Using Deep Learning and Multimodal Fundus Images". British Journal of Ophthalmology, 2022. (http://dx.doi.org/10.1136/bjo-2021-320897).</li>
	</ol>

	    <h3>Recent Uncertainty, Active Learning, and Federated  Learning Publications</h3>
	    <ol style="margin-left: 3em;">
	  <li>Kim DD, Chandra RS, Yang L, Wu J, Feng X, Atalay M, Bettegowda C, <strong>Jones C</strong>, Sair H, Liao WH, Zhu C, Zou B, Kazerooni AF, Nabavizadeh A, Jiao Z, Peng J, Bai HX, "Active Learning in Brain Tumor Segmentation with Uncertainty Sampling and Annotation Redundancy Restriction", J Imaging Inform Med. 2024 Oct;37(5):2099-2107. doi: 10.1007/s10278-024-01037-6.</li>

	  <li>Liu SZ, Vagdargi P, <strong>Jones CK</strong>, Luciano M, Anderson WS, Helm PA, Uneri A, Siewerdsen JH, Zbijewski W, and Sisniega A, "One-shot estimation of epistemic uncertainty in deep learning image formation with application to high-quality cone-beam CT reconstruction", SPIE 2024.</li>

	  <li>Duan R, Caffo B, Bai H, Sair HI, <strong>Jones CK</strong>. "Evidential Uncertainty Quantification: A Variance-Based Perspective." Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, 2024.</li>

	  <li>Yi M, Duan R, Li Z, Siewerdsen JH, Uneri A, Lee J, <strong>Jones CK</strong>. "Joint synthesis and registration of MRI and Cone-Beam CT Images using deep evidential uncertainty estimation of deformation fields." Proceedings Volume 12928, Medical Imaging 2024: Image-Guided Procedures, Robotic Interventions, and Modeling; 129280X (2024) https://doi.org/10.1117/12.3008899.</li>

	  <li>Pati S, …. <strong>Jones CK</strong>, …., Bakas S., "Federated Learning Enables Big Data for Rare Cancer Boundary Detection", Nature Communications, 2022 Dec 5;13(1):7346. doi: 10.1038/s41467-022-33407-5.</li>

	  <li><strong>Jones CK</strong>, Wang G, Yedavalli V, Sair H. "Quantifying Epistemic and Aleatoric Uncertainty in 3D U-Net Segmentation". Journal of Medical Imaging 9(3), 034002, 2022. (http://dx.doi.org/10.1117/1.JMI.9.3.034002).</li>

	  <li>Zhang X, Sisniega A, Zbijewski WB, Lee J, <strong>Jones CK</strong>, Wu P, Han R, Uneri A, Vagdargi P, Helm PA, Luciano M, Anderson WS, Siewerdsen JH. "Combining physics-based models with deep learning image synthesis and uncertainty in intraoperative cone-beam CT of the brain", Medical Physics 50(5) p. 2607-2624.</li>
	</ol>

	    <h3>Recent Deep Learning Publications</h3>
	    <ol style="margin-left: 3em;">
  <li>P Vagdargi, A Uneri, SZ Liu, <strong>CK Jones</strong>, A Sisniega, J Lee, PA Helm, RP Lee, MG Luciano, GD Hager, JH Siewerdsen "Self-Supervised Feature Detection and 3D Reconstruction for Real-Time Neuroendoscopic Guidance", IEEE Transactions in Biomedical Engineering (in press).</li>
  
  <li>Latheef AAP, Santamaria-Pang A, <strong>Jones CK</strong>, Sair HI, "Emergent Language Symbolic Autoencoder (ELSA) with Weak Supervision to Model Hierarchical Brain Networks", arXiv:2404.10031, MICCAI 2024.</li>
  
  <li>Hu Y, Huang Y, Song A, <strong>Jones CK</strong>, Siewerdsen JH, Basar B, Helm PA, Uneri A, "Probe positioning for robot-assisted intraoperative ultrasound imaging using deep reinforcement learning", Proceedings Volume 12928, Medical Imaging 2024: Image-Guided Procedures, Robotic Interventions, and Modeling; 1292803 (2024) https://doi.org/10.1117/12.3006918.</li>
  
  <li>Vagdargi P, Uneri A, Liu S, <strong>Jones CK</strong>, Sisniega A, Lee J, Helm PA, Anderson WS, Luciano M, Hager GD, Siewerdsen JH, "End-to-end 3D neuroendoscopic video reconstruction for robot-assisted ventriculostomy", Proceedings Volume 12928, Medical Imaging 2024: Image-Guided Procedures, Robotic Interventions, and Modeling; 129280M (2024) https://doi.org/10.1117/12.3008758.</li>
  
  <li>Kambli H, Santamaria-Pang A, Tarapov I, Beheshtian E, Luna L, Sair HI, <strong>Jones C</strong>, "Atlas-Based Labeling of Resting-State fMRI", Brain Connectivity, Published Online: 30 May 2024, https://doi.org/10.1089/brain.2023.0080.</li>
  
  <li>Wang Y, Peng J, Dai Y, <strong>Jones C</strong>, Sair S, Shen J, Loizou N, Wu J, Hsu WC, Imami M, Yang L, Jiao Z, Zhang P, Bai H, "Enhancing vision-language models for medical imaging: bridging the 3D gap with innovative slice selection", NeurIPS D&B Track 2024.</li>
  
  <li>Ghate S, Santamaria-Pang A, Tarapov I, Sair HI, <strong>Jones CK</strong>. "Deep Labeling of fMRI Brain Networks Using Cloud Based Processing".17th International Symposium on Visual Computing (ISVC 2022).</li>
  
  <li>Han R, <strong>Jones CK</strong>, Lee J, Wu P, Vagdargi P, Uneri A, Helm PA, Luciano M, Anderson WS, Siewerdsen JH. "Deformable MR-CT Image Registration Using an Unsupervised, Dual-Channel Network for Neurosurgical Guidance." Medical Image Analysis, 2021 Med Image Anal. 2022 Jan;75:102292. DOI: https://doi.org/10.1016/j.media.2021.102292</li>
  
  <li>Han R, <strong>Jones C.K</strong>, Ketch M, Wu P, Vagdargi P, Uneri A, Lee J, Luciano M, Anderson WS, Siewerdsen JH, "Deformable MR-CT image registration using an unsupervised end-to-end synthesis and registration network for endoscopic neurosurgery." Proc. SPIE 11598, Medical Imaging 2021: Image-Guided Procedures, Robotic Interventions, and Modeling, 1159819</li>
  
  <li>Han R, <strong>Jones CK</strong>, Wu P, Vagdargi P, Zhang X, Uneri A, Lee J, Luciano M, Anderson WS, Siewerdsen JH, "Deformable Registration of MRI to Intraoperative Cone-Beam CT of the Brain Using a Joint Synthesis and Registration Network." SPIE Medical Imaging 2022.</li>
  
  <li>Han R, <strong>Jones CK</strong>, Lee J, Zhang X, Wu P, Vagdargi P, Uneri A, Helm PA, Luciano M, Anderson WS, Siewerdsen JH. "Joint Synthesis and Registration Network for Deformable MR-CBCT Image Registration for Neurosurgical Guidance", Physics in Medicine and Biology v67, 2022.</li>
  
  <li>Huang Y, <strong>Jones CK</strong>, Zhang X, Johnston A, Waktola S, Aygun N, Witham TF, Bydon A, Theodore N, Helm PA, Siewerdsen JH, Uneri A. "Multi-perspective region-based CNNs for vertebrae labeling in intraoperative long-length images." Computer Methods and Programs in Biomedicine, Volume 227, December 2022. https://doi.org/10.1016/j.cmpb.2022.107222</li>
  
  <li>Huang Y, <strong>Jones CK</strong>, Zhang X, Johnston A, Waktola S, Aygun N, Witham TF, Bydon A, Theodore N, Helm PA, Siewerdsen JH, Uneri A. "Multi-Perspective Region-Based CNNs for Vertebrae Labeling in Intraoperative Long-Length Images." Proceedings Volume 12034, Medical Imaging 2022: Image-Guided Procedures, Robotic Interventions, and Modeling; 120340U (2022) https://doi.org/10.1117/12.2611912</li>
	</ol>

        </section>
    </main>

    <footer id="contact">
        <div class="container">
            <h2>Contact</h2>
            <div class="contact-info">
                <p>Email: craig@imagingai.org</p>
            </div>
            <p style="margin-top: 2rem;">Johns Hopkins University<br>Radiology AI Lab<br>https://rail.jhu.edu</p>
        </div>
    </footer>
</body>
</html>
