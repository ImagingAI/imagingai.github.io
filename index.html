<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dr. Craig Jones - Medical Imaging AI Researcher</title>
    <style>
        :root {
            --primary-color: #2c3e50;
            --secondary-color: #3498db;
            --accent-color: #1abc9c;
            --text-color: #333;
            --light-bg: #f9f9f9;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Helvetica Neue', Arial, sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            background-color: white;
        }

        header {
            background-color: var(--primary-color);
            color: white;
            padding: 2rem 0;
            text-align: center;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 2rem;
        }

        h1 {
            font-size: 2.5rem;
            margin-bottom: 1rem;
        }

        h2 {
            font-size: 2rem;
            margin: 2rem 0 1rem;
            color: var(--primary-color);
        }

        h3 {
            font-size: 1.5rem;
            margin: 1.5rem 0 0.5rem;
            color: var(--secondary-color);
        }

        p {
            margin-bottom: 1rem;
        }

        .profile {
            display: flex;
            align-items: center;
            gap: 2rem;
            margin: 3rem 0;
        }

        .profile-img {
            width: 200px;
            height: 200px;
            border-radius: 50%;
            object-fit: cover;
            border: 4px solid var(--secondary-color);
        }

        .profile-text {
            flex: 1;
        }

        section {
            margin: 4rem 0;
            scroll-margin-top: 2rem;
        }

        .projects {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 2rem;
        }

        .project-card {
            background-color: var(--light-bg);
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            transition: transform 0.3s ease;
        }

        .project-card:hover {
            transform: translateY(-5px);
        }

        .project-img {
            width: 100%;
            height: 200px;
            object-fit: cover;
        }

        .project-content {
            padding: 1.5rem;
        }

        .education, .publications {
            background-color: var(--light-bg);
            padding: 2rem;
            border-radius: 8px;
        }

        .education-item, .publication-item {
            margin-bottom: 1.5rem;
        }

        .year {
            font-weight: bold;
            color: var(--secondary-color);
        }

        footer {
            background-color: var(--primary-color);
            color: white;
            text-align: center;
            padding: 2rem 0;
            margin-top: 4rem;
        }

        .contact-info {
            display: flex;
            justify-content: center;
            gap: 2rem;
            margin-top: 1rem;
        }

        a {
            color: var(--secondary-color);
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        footer a {
            color: white;
        }

        nav {
            background-color: white;
            position: sticky;
            top: 0;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            z-index: 100;
        }

        nav ul {
            display: flex;
            justify-content: center;
            list-style: none;
            padding: 1rem 0;
        }

        nav li {
            margin: 0 1rem;
        }

        nav a {
            color: var(--primary-color);
            font-weight: bold;
        }

        .highlight {
            color: var(--accent-color);
        }
    </style>
</head>
<body>
    <header>
        <div class="container">
            <h1>Dr. Craig Jones</h1>
            <p>Medical Imaging AI Researcher</p>
        </div>
    </header>

    <nav>
        <ul>
            <li><a href="#about">About</a></li>
            <li><a href="#research">Research</a></li>
            <li><a href="#projects">Projects</a></li>
            <li><a href="#education">Education</a></li>
            <li><a href="#publications">Publications</a></li>
            <li><a href="#contact">Contact</a></li>
        </ul>
    </nav>

    <main class="container">
        <section id="about" class="profile">
            <img src="ckj.png" alt="Dr. Craig Jones" class="profile-img">
            <div class="profile-text">
                <h2>About Me</h2>
                <p>I am a Medical Imaging AI Researcher with expertise in developing advanced machine learning techniques for medical image analysis, diagnosis, and treatment planning. My research focuses on improving healthcare outcomes through innovative AI solutions.</p>
		<p>Currently, I am currently the Director of the IAMAI Center at NovaGen Research, and have my own Imaging Lab too.</p> 
		<p>I am a <a href="https://engineering.jhu.edu/faculty/craig-jones/">Assistant Research Professor</a> in <a href=https://www.cs.jhu.edu/">Computer Science</a> at Johns Hopkins with cross appointments in <a href="https://www.hopkinsmedicine.org/wilmer/">Ophthalmology</a>, <a href="https://www.hopkinsmedicine.org/radiology">Radiology</a>, and <a href="https://www.hopkinsmedicine.org/gastroenterology-hepatology">Gastroenterology</a>.  I am a Co-Director of the <a href="https://rail.jhu.edu">Radiology AI Lab</a>. I have four PhD students and numerous MSc and undergraduate students working on computer science, medical image processing, deep learning, and AI modeling of medical imaging and non-imaging data.</p>
		<p>I have taught Computer Vision, Medical Image Processing and Radiology for Engineer classes at Johns Hopkins. I serve as a Scientific Advisor for the <a href="https://www.cameramriafrica.org/spark">SPrint AI training for AfRican medical imaging Knowledge translation (SPARK)</a> which is part of <a href="https://www.cameramriafrica.org">CAMERA</a> program to build expertise to enable Africa to use MRI to realize their healthcare needs. I teach several modules in the SPARK program including Medical Image Processing, UNet Segmentation, Deep Learning, and How to Write a Paper.</p>
		<p>Recent conferences and journals I have reviewed for include: British Journal of Ophthalmology; Computer Methods and Programs in Biomedicine; Artificial Intelligence in Medicine; Engineering; JAMA Ophthalmology; PlosOne; Physica Scripta, Ophthalmology Retina; MICCAI
</p>
                <p>My work combines deep learning, computer vision, and medical knowledge to create AI tools that assist healthcare professionals in making more accurate and efficient diagnoses and to advance computational medical imaging AI.</p>
            </div>
        </section>

        <section id="research">
            <h2>Research Focus</h2>
            <p>My research spans several key areas in medical imaging AI:</p>
            <ul>
                <li><strong>Deep Learning for Image Segmentation:</strong> Developing neural network architectures for precise organ and lesion segmentation.</li>
                <li><strong>Multimodal Analysis:</strong> Integrating information from multiple imaging modalities (MRI, CT, PET) for comprehensive diagnosis.</li>
                <li><strong>Uncertainty:</strong> Understanding how uncertainty plays into AI both related to the input (clean labels) and output.</li>
            </ul>
        </section>

        <section id="projects">
            <h2>Featured Projects</h2>
            <div class="projects">
                <div class="project-card">
                    <img src="/api/placeholder/400/200" alt="Project 1" class="project-img">
                    <div class="project-content">
                        <h3>AI-Driven Brain Tumor Segmentation</h3>
                        <p>Developed a novel deep learning architecture for automatic segmentation of brain tumors from multimodal MRI scans, achieving state-of-the-art performance with a Dice score of 0.91.</p>
                        <p>This work enables more precise tumor volume measurement for treatment planning and monitoring.</p>
                    </div>
                </div>

                <div class="project-card">
                    <img src="/api/placeholder/400/200" alt="Project 2" class="project-img">
                    <div class="project-content">
                        <h3>Lung Nodule Detection and Classification</h3>
                        <p>Created an end-to-end system for detecting and classifying pulmonary nodules in CT scans, reducing false positive rates by 30% compared to previous methods.</p>
                        <p>The system has been deployed in a clinical trial with [Partner Hospital] to assist radiologists in early lung cancer screening.</p>
                    </div>
                </div>

                <div class="project-card">
                    <img src="/api/placeholder/400/200" alt="Project 3" class="project-img">
                    <div class="project-content">
                        <h3>Federated Learning for Medical Imaging</h3>
                        <p>Pioneered a privacy-preserving federated learning framework that enables multiple healthcare institutions to collaboratively train AI models without sharing sensitive patient data.</p>
                        <p>This approach addresses key regulatory and privacy concerns in healthcare AI deployment.</p>
                    </div>
                </div>

                <div class="project-card">
                    <img src="/api/placeholder/400/200" alt="Project 4" class="project-img">
                    <div class="project-content">
                        <h3>Multimodal Fusion for Alzheimer's Diagnosis</h3>
                        <p>Developed a multimodal deep learning approach that combines structural MRI, FDG-PET, and clinical data for early diagnosis of Alzheimer's disease.</p>
                        <p>The model achieved 94% accuracy in identifying patients with mild cognitive impairment who progressed to Alzheimer's within 3 years.</p>
                    </div>
                </div>

                <div class="project-card">
                    <img src="/api/placeholder/400/200" alt="Project 5" class="project-img">
                    <div class="project-content">
                        <h3>Explainable AI for Radiology Reports</h3>
                        <p>Created an explainable AI system that generates human-readable justifications for its findings when analyzing chest X-rays, increasing radiologist trust and adoption.</p>
                        <p>This work addresses the "black box" nature of AI diagnostics and provides transparency in clinical decision support.</p>
                    </div>
                </div>
            </div>
        </section>

        <section id="education" class="education">
            <h2>Education & Training</h2>

            <div class="education-item">
                <p class="year">1999 - 2003</p>
                <h3>Ph.D. in Physics (Medical Biophysics)</h3>
                <p>University of British Columbia</p>
                <p>Thesis: T2 Decay Curve Acquisition and Analysis in MRI: Noise Considerations, Short T2 , and B1 Field Encoding</p>
                <p>Advisor: Prof. Alex Mackay and San Xang</p>
            </div>

            <div class="education-item">
                <p class="year">1994 - 1997</p>
                <h3>M.S. in Medical Biophysics</h3>
                <p>University of Western Ontario</p>
                <p>Thesis: Quantitative Multi-Component Analysis Using Fast Spin-Echo MRI</p>
            </div>

            <div class="education-item">
                <p class="year">1988 - 1992</p>
                <h3>B.Sc. (Honours) in Mathematics and Computing Science (First Class Standing)</h3>
                <p>Simon Fraser University</p>
            </div>

            <h3>Additional Training</h3>
            <div class="education-item">
                <p class="year">20XX</p>
                <h3>Postdoctoral Research Fellowship</h3>
                <p>F.M. Kirby Center, Kennedy Krieger Institute, Johns Hopkins University</p>
                <p>Focus: [Research Focus]</p>
            </div>
        </section>

        <section id="publications" class="publications">
            <h2>Selected Publications</h2>

	    <p>
	    Below is a selection of recent papers from my full list of approximately 100 peer reviewed journal articles.
	    </p>
            <a href="https://scholar.google.com/citations?hl=en&user=uWxO67gAAAAJ&view_op=list_works&sortby=pubdate">View all publications →</a>

	    <h3>Recent Ophthalmology Publications</h3>
	    <ol style="margin-left: 3em;">
		  <li>Wang Y, Peng J, Dai Y, <strong>Jones C</strong>, Sair S, Shen J, Loizou N, Wu J, Hsu WC, Imami M, Yang L, Jiao Z, Zhang P, Bai H, "Enhancing vision-language models for medical imaging: bridging the 3D gap with innovative slice selection", NeurIPS D&B Track 2024.</li>

		  <li>TYA Liu, Y Liu, MS Gastonguay, D Midgett, N Kuo, Y Zhao, K Ullah, G Alexander, T Hartman, ND Koseoglu, <strong>C Jones</strong>, "Predicting Imminent Conversion to Exudative Age-related Macular Degeneration Using Multimodal Data and Ensemble Machine Learning", Ophthalmology Science. 2025. In Press. doi: https://doi.org/10.1016/j.xops.2025.100785</li>

		  <li>Cornelio A, Martinez AC, Lu H, <strong>Jones C</strong>, Kashani AH, "Rigid alignment method for secondary analyses of optical coherence tomography volumes", Biomed. Opt. Express 15, 938-952 (2024) https://doi.org/10.1364/BOE.508123.</li>

		  <li>Liu TYA, Koseoglu ND, <strong>Jones CK</strong>, "Self-Supervised Deep Learning—The Next Frontier", JAMA Ophthalmol. Published online February 8, 2024. doi:10.1001/jamaophthalmol.2023.6650.</li>

		  <li>Wu J, Koseoglu ND, <strong>Jones CK</strong>, Liu TYA. "Vision transformers: The next frontier for deep learning-based ophthalmic image analysis", Saudi Journal of Ophthalmology:, July 14, 2023. | DOI: 10.4103/sjopt.sjopt_91_23.</li>

		  <li><strong>Jones CK</strong>, Li B, Wu JH, Nakaguchi T, Xuan P, Liu TYA. "Comparative analysis of alignment algorithms for macular optical coherence tomography imaging", Int J Retin Vitr 2023;9(60) 2023, https://doi.org/10.1186/s40942-023-00497-2.</li>

		  <li>Kashani AH, Liu TYA, <strong>Jones CK</strong>. "Optical Coherence Tomography Angiography, Artificial Intelligence, and the Missing Capillaries", JAMA Ophthalmol. Published online May 25, 2023. doi:10.1001/jamaophthalmol.2023.1829.</li>

		  <li>Liu Y, Ota M, Han R, Siewerdsen J, Liu TYA, <strong>Jones CK</strong>, "Active Shape Model Registration of Ocular Structures in Computed Tomography Images." Physics in Medicine and Biology, 2022 (https://doi.org/10.1088/1361-6560/ac9a98).</li>

		  <li>Liu TY, Ling C, Hahn L, <strong>Jones CK</strong>, Boon C, Singh M. "Prediction of Visual Impairment in Retinitis Pigmentosa Using Deep Learning and Multimodal Fundus Images". British Journal of Ophthalmology, 2022. (http://dx.doi.org/10.1136/bjo-2021-320897).</li>
	</ol>

	    <h3>Recent Uncertainty, Active Learning, and Federated  Learning Publications</h3>
	    <ol style="margin-left: 3em;">
	  <li>Kim DD, Chandra RS, Yang L, Wu J, Feng X, Atalay M, Bettegowda C, <strong>Jones C</strong>, Sair H, Liao WH, Zhu C, Zou B, Kazerooni AF, Nabavizadeh A, Jiao Z, Peng J, Bai HX, "Active Learning in Brain Tumor Segmentation with Uncertainty Sampling and Annotation Redundancy Restriction", J Imaging Inform Med. 2024 Oct;37(5):2099-2107. doi: 10.1007/s10278-024-01037-6.</li>

	  <li>Liu SZ, Vagdargi P, <strong>Jones CK</strong>, Luciano M, Anderson WS, Helm PA, Uneri A, Siewerdsen JH, Zbijewski W, and Sisniega A, "One-shot estimation of epistemic uncertainty in deep learning image formation with application to high-quality cone-beam CT reconstruction", SPIE 2024.</li>

	  <li>Duan R, Caffo B, Bai H, Sair HI, <strong>Jones CK</strong>. "Evidential Uncertainty Quantification: A Variance-Based Perspective." Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, 2024.</li>

	  <li>Yi M, Duan R, Li Z, Siewerdsen JH, Uneri A, Lee J, <strong>Jones CK</strong>. "Joint synthesis and registration of MRI and Cone-Beam CT Images using deep evidential uncertainty estimation of deformation fields." Proceedings Volume 12928, Medical Imaging 2024: Image-Guided Procedures, Robotic Interventions, and Modeling; 129280X (2024) https://doi.org/10.1117/12.3008899.</li>

	  <li>Pati S, …. <strong>Jones CK</strong>, …., Bakas S., "Federated Learning Enables Big Data for Rare Cancer Boundary Detection", Nature Communications, 2022 Dec 5;13(1):7346. doi: 10.1038/s41467-022-33407-5.</li>

	  <li><strong>Jones CK</strong>, Wang G, Yedavalli V, Sair H. "Quantifying Epistemic and Aleatoric Uncertainty in 3D U-Net Segmentation". Journal of Medical Imaging 9(3), 034002, 2022. (http://dx.doi.org/10.1117/1.JMI.9.3.034002).</li>

	  <li>Zhang X, Sisniega A, Zbijewski WB, Lee J, <strong>Jones CK</strong>, Wu P, Han R, Uneri A, Vagdargi P, Helm PA, Luciano M, Anderson WS, Siewerdsen JH. "Combining physics-based models with deep learning image synthesis and uncertainty in intraoperative cone-beam CT of the brain", Medical Physics 50(5) p. 2607-2624.</li>
	</ol>

	    <h3>Recent Deep Learning Publications</h3>
	    <ol style="margin-left: 3em;">
		  <li>Kim DD, Chandra RS, Yang L, Wu J, Feng X, Atalay M, Bettegowda C, <strong>Jones C</strong>, Sair H, Liao WH, Zhu C, Zou B, Kazerooni AF, Nabavizadeh A, Jiao Z, Peng J, Bai HX, "Active Learning in Brain Tumor Segmentation with Uncertainty Sampling and Annotation Redundancy Restriction", J Imaging Inform Med. 2024 Oct;37(5):2099-2107. doi: 10.1007/s10278-024-01037-6.</li>

		  <li>Feng X, Ghimire K, Kim DD, Chandra RS, Zhang H, Peng J, Han B, Huang G, Chen Q, Patel S, Bettegowda C, Sair HI, <strong>Jones CK</strong>, Jiao Z, Yang L, Bai H. "Brain Tumor Segmentation for Multi-Modal MRI with Missing Information", J Digit Imaging. 2023 Oct;36(5):2075-2087. doi: 10.1007/s10278-023-00860-7. Epub 2023 Jun 20.</li>

		  <li>Pati S, …. <strong>Jones CK</strong>, …., Bakas S., "Federated Learning Enables Big Data for Rare Cancer Boundary Detection", Nature Communications, 2022 Dec 5;13(1):7346. doi: 10.1038/s41467-022-33407-5.</li>

		  <li>Raman A, <strong>Jones CK</strong>, Weiss C. "Machine Learning for Hepatocellular Carcinoma Segmentation on MRI". Radiology 304(3), 2022. (https://doi.org/10.1148/radiol.212386)</li>

		  <li><strong>Jones CK</strong>, Wang G, Yedavalli V, Sair H. "Quantifying Epistemic and Aleatoric Uncertainty in 3D U-Net Segmentation". Journal of Medical Imaging 9(3), 034002, 2022. (http://dx.doi.org/10.1117/1.JMI.9.3.034002).</li>
	</ol>

        </section>
    </main>

    <footer id="contact">
        <div class="container">
            <h2>Contact</h2>
            <div class="contact-info">
                <p>Email: craig@imagingai.org</p>
            </div>
            <p style="margin-top: 2rem;">Johns Hopkins University<br>Radiology AI Lab<br>https://rail.jhu.edu</p>
        </div>
    </footer>
</body>
</html>
